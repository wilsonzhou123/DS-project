{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T17:06:24.669739Z","iopub.execute_input":"2024-07-23T17:06:24.670022Z","iopub.status.idle":"2024-07-23T17:06:25.751091Z","shell.execute_reply.started":"2024-07-23T17:06:24.669998Z","shell.execute_reply":"2024-07-23T17:06:25.749929Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:06:25.753748Z","iopub.execute_input":"2024-07-23T17:06:25.754691Z","iopub.status.idle":"2024-07-23T17:06:39.771823Z","shell.execute_reply.started":"2024-07-23T17:06:25.754654Z","shell.execute_reply":"2024-07-23T17:06:39.770364Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom datasets import load_dataset, Dataset\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, GPT2Model\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom bayes_opt import BayesianOptimization\nimport random\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:06:39.773737Z","iopub.execute_input":"2024-07-23T17:06:39.774103Z","iopub.status.idle":"2024-07-23T17:07:01.195956Z","shell.execute_reply.started":"2024-07-23T17:06:39.774068Z","shell.execute_reply":"2024-07-23T17:07:01.195157Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-23 17:06:47.852268: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-23 17:06:47.852370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-23 17:06:47.992174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load SpaCy's language model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Download stopwords if not already done\nnltk.download('stopwords')\n\n# Function to preprocess text\ndef preprocess_text(text):\n    # Remove stop words and lemmatize words\n    doc = nlp(text)\n    stop_words = set(stopwords.words('english'))\n    lemmatized_words = [token.lemma_ for token in doc if token.is_alpha and token.text not in stop_words]\n    return \" \".join(lemmatized_words)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:07:01.197951Z","iopub.execute_input":"2024-07-23T17:07:01.198561Z","iopub.status.idle":"2024-07-23T17:07:02.580532Z","shell.execute_reply.started":"2024-07-23T17:07:01.198499Z","shell.execute_reply":"2024-07-23T17:07:02.579658Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# set the random seed\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    \n# Load the dataset\ndataset = load_dataset(\"SetFit/bbc-news\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:07:02.581777Z","iopub.execute_input":"2024-07-23T17:07:02.582071Z","iopub.status.idle":"2024-07-23T17:07:08.342889Z","shell.execute_reply.started":"2024-07-23T17:07:02.582046Z","shell.execute_reply":"2024-07-23T17:07:08.341851Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/880 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3d43ea6945242e49d37ed30998f933f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.87M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cd70790f06c45c3ad5c03554c99778d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af59152bfa4e45918afabbf49dd51bf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1225 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35730c1ac2584f8dad3c2967459d34bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1371e94a5b44133bfe5fb6fdc28e599"}},"metadata":{}}]},{"cell_type":"code","source":"# Convert the training and test datasets to DataFrames\ntrain_df = dataset['train'].to_pandas()\ntest_df = dataset['test'].to_pandas()\n\n# Apply preprocessing to the text column\ntrain_df['text'] = train_df['text'].apply(preprocess_text)\ntest_df['text'] = test_df['text'].apply(preprocess_text)\n\n\n# Display some examples of preprocessed text\nprint(\"Examples of preprocessed training text:\")\nprint(train_df['text'].head())\n\nprint(\"\\nExamples of preprocessed test text:\")\nprint(test_df['text'].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:07:08.344048Z","iopub.execute_input":"2024-07-23T17:07:08.344359Z","iopub.status.idle":"2024-07-23T17:09:36.662626Z","shell.execute_reply.started":"2024-07-23T17:07:08.344332Z","shell.execute_reply":"2024-07-23T17:09:36.661379Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Examples of preprocessed training text:\n0    wale want rugby league training wale could fol...\n1    china aviation seek rescue deal scandal hit je...\n2    rock band break ticket record smash irish box ...\n3    market signal brazilian recovery brazilian sto...\n4    tough rule ringtone seller firm flout rule rin...\nName: text, dtype: object\n\nExamples of preprocessed test text:\n0    carry star patsy rowlands die actress patsy ro...\n1    sydney host north v south game sydney host nor...\n2    uk coal plunge deep loss share uk coal fall mi...\n3    blair join school sailing trip prime minister ...\n4    bath face tindall ultimatum mike tindall agent...\nName: text, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine the training and test DataFrames\nall_df = pd.concat([train_df, test_df])\n\n# 30 % data are used for test\ntrain_df, test_df = train_test_split(all_df, test_size=0.2, random_state=seed)\n\n#  20% of training set are divided to be validation set\ntrain_df, val_df = train_test_split(train_df, test_size=0.125, random_state=seed)\n\n\nprint(train_df.head())\nprint(val_df.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:09:36.664492Z","iopub.execute_input":"2024-07-23T17:09:36.664844Z","iopub.status.idle":"2024-07-23T17:09:36.693375Z","shell.execute_reply.started":"2024-07-23T17:09:36.664819Z","shell.execute_reply":"2024-07-23T17:09:36.692365Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                                                  text  label label_text\n475  online common spark debate online community se...      0       tech\n86   kewell wait injury drag liverpool winger harry...      2      sport\n188  us budget deficit reach us budget deficit set ...      1   business\n576  wale get williams fitness boost wale hopeful o...      2      sport\n22   beckham virus spot net virus writer trade inte...      0       tech\n                                                  text  label label_text\n648  tory unveil quango blitz plan plan abolish qua...      4   politics\n93   howard truante play snooker conservative leade...      4   politics\n5    banker lose sexism claim former executive lond...      1   business\n57   robinson six nation england captain jason robi...      2      sport\n837  weng shock newcastle dip arsenal manager arsen...      2      sport\n                                                  text  label label_text\n414  greek pair attend drug hear greek sprinter kos...      2      sport\n420  microsoft seek spyware trojan microsoft invest...      0       tech\n419  fox attack blair tory lie tony blair lie take ...      4   politics\n416  unclear future striker baros liverpool forward...      2      sport\n7    saab build cadillac sweden general motor world...      1   business\n","output_type":"stream"}]},{"cell_type":"code","source":"# turn DataFrames into Dataset object\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:09:36.694406Z","iopub.execute_input":"2024-07-23T17:09:36.694686Z","iopub.status.idle":"2024-07-23T17:09:36.733634Z","shell.execute_reply.started":"2024-07-23T17:09:36.694663Z","shell.execute_reply":"2024-07-23T17:09:36.732771Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"Number of train data: \", len(train_dataset))\nprint(\"Number of val data: \", len(val_dataset))\nprint(\"Number of test data: \", len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:09:36.734708Z","iopub.execute_input":"2024-07-23T17:09:36.734952Z","iopub.status.idle":"2024-07-23T17:09:36.740005Z","shell.execute_reply.started":"2024-07-23T17:09:36.734931Z","shell.execute_reply":"2024-07-23T17:09:36.739162Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of train data:  1557\nNumber of val data:  223\nNumber of test data:  445\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Load GPT2Tokenizer and Model\ntokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n\n\n\n# Add pad_token\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nmodel = GPT2ForSequenceClassification.from_pretrained('distilgpt2', num_labels=5)\n\n# Resize token embeddings to match the tokenizer length\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Set the padding token ID in the model configuration\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:09:36.742854Z","iopub.execute_input":"2024-07-23T17:09:36.743118Z","iopub.status.idle":"2024-07-23T17:09:48.701106Z","shell.execute_reply.started":"2024-07-23T17:09:36.743095Z","shell.execute_reply":"2024-07-23T17:09:48.700140Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7181ad0bff16440a93ca9afe076e7cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c0d78efc84144da8b3b1d75d4764a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24093257da01487dbe14f557ca77863b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"025282602fa74f4da646c1708089c868"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6bd4dde211041b488abae5c1792b446"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a706f39bc4ec4d75b352ce0dc3453c18"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n\ntrain_data1 = train_dataset.map(tokenize_function, batched=True)\nval_data1 = val_dataset.map(tokenize_function, batched=True)\ntest_data1 = test_dataset.map(tokenize_function, batched=True)\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Define compute metrics function\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.argmax(axis=1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n    acc = accuracy_score(labels, predictions)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    seed=seed,\n)\n\n# Define Trainer\ntrainer1 = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data1,\n    eval_dataset=val_data1,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\n# Train the model\ntrainer1.train()\n\n# Evaluate the best model on the test set\neval_result = trainer1.evaluate(test_data1)\nprint(f\"Final evaluation results on test set: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:09:48.702304Z","iopub.execute_input":"2024-07-23T17:09:48.702622Z","iopub.status.idle":"2024-07-23T17:18:54.816539Z","shell.execute_reply.started":"2024-07-23T17:09:48.702596Z","shell.execute_reply":"2024-07-23T17:18:54.815491Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c35700fb1e44b5da2726f47b30b3ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af3684cc4a942e295426fe835d47d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"406ac703e014421a878dcbdc309ed399"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:45, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.261627</td>\n      <td>0.928251</td>\n      <td>0.929133</td>\n      <td>0.937352</td>\n      <td>0.928251</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.235765</td>\n      <td>0.964126</td>\n      <td>0.963739</td>\n      <td>0.967032</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.167404</td>\n      <td>0.959641</td>\n      <td>0.959386</td>\n      <td>0.961301</td>\n      <td>0.959641</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.237905</td>\n      <td>0.968610</td>\n      <td>0.968045</td>\n      <td>0.971080</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.177301</td>\n      <td>0.973094</td>\n      <td>0.972698</td>\n      <td>0.974953</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.226000</td>\n      <td>0.130876</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.226000</td>\n      <td>0.189309</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.226000</td>\n      <td>0.203833</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.226000</td>\n      <td>0.186068</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.226000</td>\n      <td>0.182668</td>\n      <td>0.973094</td>\n      <td>0.972855</td>\n      <td>0.974410</td>\n      <td>0.973094</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results on test set: {'eval_loss': 0.21280071139335632, 'eval_accuracy': 0.9662921348314607, 'eval_f1': 0.9665312461563137, 'eval_precision': 0.9679517340543468, 'eval_recall': 0.9662921348314607, 'eval_runtime': 4.481, 'eval_samples_per_second': 99.308, 'eval_steps_per_second': 6.249, 'epoch': 10.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"enhanced_prompts = [\n\"What is the central focus of this newspaper article?\",\n\"How would you formulate the main theme of this message?\",\n\"Where is this story most likely to be found in the newspaper?\",\n\"How would you define the primary subject of this news?\",\n\"What is the main topic of this news?\",\n\"Which category is best suited for this news?\",\n\"What is the main topic of this news article?\",\n\"What is central to this news article?\",\n\"Which part of the newspaper is most likely to contain this news?\",\n\"Where in the newspaper is this news most likely to be located?\",\n\"How would you explain the main topic of this news?\",\n\"Which section of the newspaper is this news most likely to be found in?\",\n\"In what section of the newspaper is this news most likely to be found?\",\n\"Which category is the best match for this news article?\",\n\"In which category does this news article best fit?\",\n\"Which category does this news fall into?\",\n\"Which category is most appropriate for this news?\",\n\"What category does this news belong to?\",\n\"Which section of the newspaper will most likely contain this news?\",\n\"In which section of the newspaper is this news story most likely to appear?\",\n\"What is the central purpose of this news article?\",\n\"In which section of the newspaper would one likely find this news item?\",\n\"How would you summarize the central theme of this message?\",\n\"In which section of the newspaper is this news most likely?\",\n\"Which part of the newspaper is likely to contain this news?\",\n\"Which category does this news best fit into?\",\n\"How would you define the main topic of this news?\",\n\"Which category best matches this news article?\",\n\"What is the main emphasis of this news article?\",\n\"How would you describe the main topic of this news?\",\n\"In which section of the newspaper would this news item most likely be found?\",\n\"How would you characterize the main theme of this message?\",\n\"Where in the newspaper is this news story most likely to be found?\",\n\"What is your description of the main theme of this news?\",\n\"Which category is best for this news article?\",\n\"What is the main point of this press article?\",\n\"In your opinion, what is the main objective of this news?\",\n\"In which section of the newspaper is this news most likely to appear?\",\n\"What category does this news article fall under?\",\n\"In what section of the newspaper is this news most likely to appear?\",\n\"Under which category does this news article fit best?\",\n\"What category does this news article belong to?\",\n\"Where in the newspaper is this news most likely to appear?\",\n\"What is your description of the main topic of this news story?\",\n\"In which section of the newspaper would this news most likely be found?\",\n\"How would you describe the main theme of this message?\",\n\"Which section of the newspaper is most likely to contain this news?\",\n\"Where in the newspaper is this news most likely to be found?\",\n\"In which section of the newspaper is this news most likely to be found?\",\n\"In which section of the newspaper are you most likely to find this news?\",\n\"What is this news article focused on?\",\n\"In what part of the newspaper would this news most likely appear?\",\n\"How would you articulate the primary subject of this news?\",\n\"What do you think is the main focus of this message?\",\n\"What is the main emphasis of this news?\",\n\"How would you define the main theme of this message?\",\n\"Which part of the newspaper would most likely contain this news?\",\n\"Which category best fits this news?\",\n\"How would you explain the main theme of this news?\",\n\"Which category is best suited for this news article?\",\n\"What do you think is the main focus of this news?\",\n\"Which category does this news article best fit into?\",\n\"How would you describe the main topic of this news story?\",\n\"What is the main focus of this news?\",\n\"In which part of the newspaper is this news likely to be found?\",\n\"In which category does this news article belong?\",\n\"Which category best suits this news article?\",\n\"What do you think is the main objective of this news?\",\n\"How would you summarize the central theme of this news?\",\n\"What would you say is the primary focus of this news?\",\n\"How do you describe the main topic of this news story?\",\n\"How would you characterize the main topic of this news story?\",\n\"How would you describe the main theme of this news story?\",\n\"What is the primary focus of this news article?\",\n\"How would you define the primary topic of this news item?\",\n\"Which section of the newspaper is most likely to publish this story?\",\n\"What is the main focus of this news article?\",\n\"What is the main theme of this news?\",\n\"In which category does this news article fit best?\",\n\"What is your description of the main subject of this news?\",\n\"What is your description of the main topic of this news?\",\n\"How would you articulate the main subject of this news?\",\n\"How would you explain the main subject of this news?\",\n\"What category does this newspaper article belong to?\",\n\"Which section of the newspaper is most likely to contain this news story?\",\n\"How would you phrase the main subject of this news story?\",\n\"Where in the newspaper might this news be found?\",\n\"What is the central point of this news article?\",\n\"Which category best fits this news article?\",\n\"What is the main purpose of this press article?\",\n\"What is the main subject of this news article?\",\n\"How would you characterize the main subject of this news?\",\n\"Which section of the newspaper is most likely to feature this news?\",\n\"In which part of the newspaper is this news most likely to be found?\",\n\"In which section of the newspaper is it most likely to find this news?\",\n\"In which part of the newspaper is this news most likely to appear?\",\n\"What is the main topic of this article?\",\n\"What category does this news article fall into?\",\n\"Into which category does this news article best fit?\",\n\"Which category is most suitable for this news article?\",\n\"How would you phrase the primary topic of this news story?\",\n\"In which section of the newspaper would this news likely be found?\",\n\"What would you say is the main focus of this news?\",\n\"How would you explain the main theme of this message?\",\n\"In which part of the newspaper would this news most likely appear?\",\n\"Which category does this news article fall under?\",\n\"How would you describe the main theme of this news?\",\n\"What is the main point of this news?\",\n\"What is the key focus of this news article?\",\n\"In which section of the newspaper would this news story likely be found?\",\n\"How would you articulate the main point of this news story?\",\n\"Which part of the newspaper would most likely contain this news story?\",\n\"What is the central focus of this news article?\",\n\"What is the main point of this news article?\",\n\"What category is this news article in?\",\n\"How would you characterize the main topic of this news?\",\n\"Under which category does this news article best fit?\",\n\"What category best fits this news article?\",\n\"Which category is the best match for this news story?\",\n\"Which section of the newspaper is this news most likely to be in?\",\n\"How would you define the main subject of this news?\",\n\"Which part of the newspaper would most likely feature this news?\",\n\"In which section of the newspaper is this news story most likely to be found?\",\n\"Which category does this news article best fit under?\",\n\"How would you summarize the central theme of this news story?\",\n\"What is the focus of this news article?\",\n\"How would you articulate the main theme of this news story?\",\n\"Which category is most appropriate for this news article?\",\n\"How would you explain the main topic of this news story?\",\n\"Which category does this news article belong to?\",\n\"In which section of the newspaper is this news most likely to be published?\",\n\"How would you describe the main subject of this news?\",\n\"How would you express the main topic of this news?\",\n\"What is the central focus of this news?\",\n\"How would you articulate the main topic of this news?\"\n]\n\nenhanced_prompts1= [ \n\"What category best fits this news article?\",\n\"How would you describe the main topic of this news?\",\n\"In which section of the newspaper would this news likely be found?\",\n\"What is the primary focus of this news article?\",\n\"Which category does this news article fall under?\",\n\"In which category does this news article belong?\",\n\"Which category is most appropriate for this news article?\",\n\"Under which category does this news article best fit?\",\n\"Which category is the best match for this news article?\",\n\"Into which category does this news article best fit?\",\n\"Which category is most suitable for this news article?\",\n\"How would you define the primary subject of this news?\",\n\"How would you summarize the central theme of this news?\",\n\"What would you say is the primary focus of this news?\",\n\"How would you explain the main subject of this news?\",\n\"How would you characterize the main topic of this news?\",\n\"What is your description of the main topic of this news?\",\n\"How would you articulate the primary subject of this news?\",\n\"Which section of the newspaper is most likely to feature this news?\",\n\"In what section of the newspaper is this news most likely to appear?\",\n\"Which section of the newspaper is this news most likely to be found in?\",\n\"Which part of the newspaper would most likely feature this news?\",\n\"Which section of the newspaper is most likely to contain this news?\",\n\"In what section of the newspaper is this news most likely to be found?\",\n\"Where in the newspaper is this news most likely to be located?\",\n\"What is the main emphasis of this news article?\",\n\"What is the central focus of this news article?\",\n\"What is the main point of this news article?\",\n\"What is the main subject of this news article?\",\n\"What is the main focus of this news article?\",\n\"What is the key focus of this news article?\",\n\"What is the main topic of this news article?\",\n\"What category best fits this news article: business, entertainment, politics, sport or tech?\",\n\"How would you describe the main topic of this news: business, entertainment, politics, sport or tech?\",\n\"In which section of the newspaper would this news likely be found: business, entertainment, politics, sport or tech?\",\n\"What is the primary focus of this news article: business, entertainment, politics, sport or tech?\",\n\"Which category does this news article fall under: business, entertainment, politics, sport or tech?\",\n\"In which category does this news article belong: business, entertainment, politics, sport or tech?\",\n\"Which category is most appropriate for this news article: business, entertainment, politics, sport or tech?\",\n\"Under which category does this news article best fit: business, entertainment, politics, sport or tech?\",\n\"Which category is the best match for this news article: business, entertainment, politics, sport or tech?\",\n\"Into which category does this news article best fit: business, entertainment, politics, sport or tech?\",\n\"Which category is most suitable for this news article: business, entertainment, politics, sport or tech?\",\n\"How would you define the primary subject of this news: business, entertainment, politics, sport or tech?\",\n\"How would you summarize the central theme of this news: business, entertainment, politics, sport or tech?\",\n\"What would you say is the primary focus of this news: business, entertainment, politics, sport or tech?\",\n\"How would you explain the main subject of this news: business, entertainment, politics, sport or tech?\",\n\"How would you characterize the main topic of this news: business, entertainment, politics, sport or tech?\",\n\"What is your description of the main topic of this news: business, entertainment, politics, sport or tech?\",\n\"How would you articulate the primary subject of this news: business, entertainment, politics, sport or tech?\",\n\"Which section of the newspaper is most likely to feature this news: business, entertainment, politics, sport or tech?\",\n\"In what section of the newspaper is this news most likely to appear: business, entertainment, politics, sport or tech?\",\n\"Which section of the newspaper is this news most likely to be found in: business, entertainment, politics, sport or tech?\",\n\"Which part of the newspaper would most likely feature this news: business, entertainment, politics, sport or tech?\",\n\"Which section of the newspaper is most likely to contain this news: business, entertainment, politics, sport or tech?\",\n\"In what section of the newspaper is this news most likely to be found: business, entertainment, politics, sport or tech?\",\n\"Where in the newspaper is this news most likely to be located: business, entertainment, politics, sport or tech?\",\n\"What is the main emphasis of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the central focus of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the main point of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the main subject of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the main focus of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the key focus of this news article: business, entertainment, politics, sport or tech?\",\n\"What is the main topic of this news article: business, entertainment, politics, sport or tech?\",\n\"What category best fits this news article: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"How would you describe the main topic of this news: business, entertainment, politics, sport or tech? Example: 'markets signal brazilian recovery the brazilian stock market has risen to a record high as investors display growing confidence in the durability of the country s economic recovery' is business.\",\n\"In which section of the newspaper would this news likely be found: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"What is the primary focus of this news article: business, entertainment, politics, sport or tech? Example: 'markets signal brazilian recovery the brazilian stock market has risen to a record high as investors display growing confidence in the durability of the country s economic recovery' is business.\",\n\"Which category does this news article fall under: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"In which category does this news article belong: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"Which category is most appropriate for this news article: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\",\n\"Under which category does this news article best fit: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"Which category is the best match for this news article: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\",\n\"Into which category does this news article best fit: business, entertainment, politics, sport or tech? Example: 'rock band u2 break ticket record u2 have smashed irish box office records with ticket sales for their dublin concerts after more than 150 000 were sold within 50 minutes' is entertainment.\",\n\"Which category is most suitable for this news article: business, entertainment, politics, sport or tech? Example: 'markets signal brazilian recovery the brazilian stock market has risen to a record high as investors display growing confidence in the durability of the country s economic recovery' is business.\",\n\"How would you define the primary subject of this news: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"How would you summarize the central theme of this news: business, entertainment, politics, sport or tech? Example: 'rock band u2 break ticket record u2 have smashed irish box office records with ticket sales for their dublin concerts after more than 150 000 were sold within 50 minutes' is entertainment.\",\n\"What would you say is the primary focus of this news: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"How would you explain the main subject of this news: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"How would you characterize the main topic of this news: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\",\n\"What is your description of the main topic of this news: business, entertainment, politics, sport or tech? Example: 'rock band u2 break ticket record u2 have smashed irish box office records with ticket sales for their dublin concerts after more than 150 000 were sold within 50 minutes' is entertainment.\",\n\"How would you articulate the primary subject of this news: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"Which section of the newspaper is most likely to feature this news: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\",\n\"In what section of the newspaper is this news most likely to appear: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"Which section of the newspaper is this news most likely to be found in: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"Which part of the newspaper would most likely feature this news: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\",\n\"Which section of the newspaper is most likely to contain this news: business, entertainment, politics, sport or tech? Example: 'markets signal brazilian recovery the brazilian stock market has risen to a record high as investors display growing confidence in the durability of the country s economic recovery' is business.\",\n\"In what section of the newspaper is this news most likely to be found: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"Where in the newspaper is this news most likely to be located: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"What is the main emphasis of this news article: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"What is the central focus of this news article: business, entertainment, politics, sport or tech? Example: 'rock band u2 break ticket record u2 have smashed irish box office records with ticket sales for their dublin concerts after more than 150 000 were sold within 50 minutes' is entertainment.\",\n\"What is the main point of this news article: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"What is the main subject of this news article: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"What is the main focus of this news article: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\",\n\"What is the key focus of this news article: business, entertainment, politics, sport or tech? Example: 'iraq advice claim sparks new row the tories say ministers must respond in parliament to claims that the legal advice used to justify the iraq war was drawn up at number 10' is politics.\",\n\"What is the main topic of this news article: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\" ]","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:18:54.818375Z","iopub.execute_input":"2024-07-23T17:18:54.818682Z","iopub.status.idle":"2024-07-23T17:18:54.844834Z","shell.execute_reply.started":"2024-07-23T17:18:54.818657Z","shell.execute_reply":"2024-07-23T17:18:54.843997Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# load Sentence Transformer model\nembedmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# generate embeddings for each prompt\nprompt_embeddings = embedmodel.encode(enhanced_prompts)\nprompt_embeddings1 = embedmodel.encode(enhanced_prompts1)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:18:54.845937Z","iopub.execute_input":"2024-07-23T17:18:54.846272Z","iopub.status.idle":"2024-07-23T17:19:05.443428Z","shell.execute_reply.started":"2024-07-23T17:18:54.846239Z","shell.execute_reply":"2024-07-23T17:19:05.442560Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4233ff8f1fd64b3983efb33bd8c7131c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dcc7ddbc3354349a8563bcbe1a1aeff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08c82ed8820481299ee4f3cceea34a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef3cd02e7e654d0da7f0d0cec50b4624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b7fd76d0ae46039bf1123ce736f5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d66463c8964ed4a1ec4962e2b69216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0007e58a94ce4d329e22f2d219218b7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e684c67d204841b549bcde233a0883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97e44a03a7341be977f3833810f8340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9444d7a8ad744e998257218e321ebb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef39c77c9fd465bb7edde7a8ebdd30c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9277f248de8e44b3bac3e9e476ebbf56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f770ee5ae51f4eefb4f7ce5f849dc6d9"}},"metadata":{}}]},{"cell_type":"code","source":"# classify function\ndef classify_article_with_prompt_embedding(prompt_embedding, article_text):\n    prompt_text = \" \".join(map(str, prompt_embedding))\n    input_text = f\"{prompt_text} {article_text}\"\n    inputs = tokenizer(input_text, truncation=True, max_length=512, padding='max_length', return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    label_id = outputs.logits.argmax(dim=1).item()\n    return label_id\n\ndef evaluate_prompt_embedding(prompt_embedding):\n    predictions = [classify_article_with_prompt_embedding(prompt_embedding, article_text) for article_text in train_dataset['text']]\n    return accuracy_score(train_dataset['label'], predictions)\n\n# Bayesian optimization function\ndef black_box_function(prompt_idx):\n    prompt_embedding = prompt_embeddings[int(prompt_idx)]\n    return evaluate_prompt_embedding(prompt_embedding)\n\npbounds = {'prompt_idx': (0, len(prompt_embeddings) - 1)}\n\noptimizer = BayesianOptimization(\n    f=black_box_function,\n    pbounds=pbounds,\n    random_state=42,\n)\n\noptimizer.maximize(\n    init_points=5,\n    n_iter=15,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:19:05.444862Z","iopub.execute_input":"2024-07-23T17:19:05.445303Z","iopub.status.idle":"2024-07-23T17:31:43.709614Z","shell.execute_reply.started":"2024-07-23T17:19:05.445270Z","shell.execute_reply":"2024-07-23T17:31:43.708769Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"|   iter    |  target   | prompt... |\n-------------------------------------\n| \u001b[30m1         | \u001b[30m0.1843    | \u001b[30m50.19     |\n| \u001b[30m2         | \u001b[30m0.1843    | \u001b[30m127.4     |\n| \u001b[30m3         | \u001b[30m0.1747    | \u001b[30m98.09     |\n| \u001b[30m4         | \u001b[30m0.1843    | \u001b[30m80.22     |\n| \u001b[30m5         | \u001b[30m0.1843    | \u001b[30m20.91     |\n| \u001b[30m6         | \u001b[30m0.1843    | \u001b[30m50.29     |\n| \u001b[30m7         | \u001b[30m0.1843    | \u001b[30m67.62     |\n| \u001b[35m8         | \u001b[35m0.2351    | \u001b[35m0.0       |\n| \u001b[30m9         | \u001b[30m0.1843    | \u001b[30m3.928     |\n| \u001b[30m10        | \u001b[30m0.2351    | \u001b[30m0.9827    |\n| \u001b[30m11        | \u001b[30m0.2351    | \u001b[30m35.59     |\n| \u001b[30m12        | \u001b[30m0.1843    | \u001b[30m33.05     |\n| \u001b[30m13        | \u001b[30m0.1843    | \u001b[30m37.27     |\n| \u001b[30m14        | \u001b[30m0.1843    | \u001b[30m34.81     |\n| \u001b[30m15        | \u001b[30m0.2351    | \u001b[30m0.4914    |\n| \u001b[30m16        | \u001b[30m0.1843    | \u001b[30m36.12     |\n| \u001b[30m17        | \u001b[30m0.1747    | \u001b[30m1.456     |\n| \u001b[30m18        | \u001b[30m0.2351    | \u001b[30m0.7515    |\n| \u001b[30m19        | \u001b[30m0.2351    | \u001b[30m35.34     |\n| \u001b[30m20        | \u001b[30m0.1747    | \u001b[30m114.1     |\n=====================================\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Find the maximum target value\nmax_target_value = max(res['target'] for res in optimizer.res)\n\n# Step 2: Collect all unique prompt indices with the maximum target value\nbest_prompt_indices = [int(res['params']['prompt_idx']) for res in optimizer.res if res['target'] == max_target_value]\nunique_best_prompt_indices = list(set(best_prompt_indices))\n\n# Step 3: Get the unique embeddings\nbest_prompt_embeddings = [prompt_embeddings[idx] for idx in unique_best_prompt_indices]\n\n# Step 4: Find the top one most similar prompt for each of the best embeddings\nall_top_similar_prompts_dict = {}\n\nfor idx, best_prompt_embedding in enumerate(best_prompt_embeddings):\n    similarities = cosine_similarity(best_prompt_embedding[np.newaxis, :], prompt_embeddings)[0]\n    # Get the index of the most similar prompt for each best embedding\n    top_index = np.argmax(similarities)\n    # Collect the most similar prompt\n    top_similar_prompt = enhanced_prompts[top_index]\n    all_top_similar_prompts_dict[unique_best_prompt_indices[idx]] = top_similar_prompt\n\n# Output best prompt embedding indices and their corresponding top one similar prompts\nprint(\"Best prompt embedding indices and their top one similar prompts:\")\nfor index, prompt in all_top_similar_prompts_dict.items():\n    print(f\"Index: {index}, Top Similar Prompt: {prompt}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:31:43.710728Z","iopub.execute_input":"2024-07-23T17:31:43.711019Z","iopub.status.idle":"2024-07-23T17:31:43.723750Z","shell.execute_reply.started":"2024-07-23T17:31:43.710993Z","shell.execute_reply":"2024-07-23T17:31:43.722519Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Best prompt embedding indices and their top one similar prompts:\nIndex: 0, Top Similar Prompt: What is the central focus of this newspaper article?\nIndex: 35, Top Similar Prompt: What is the main point of this press article?\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    seed= seed,\n)\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Iterate over each index and its most similar prompt\nfor idx, prompts in all_top_similar_prompts_dict.items():\n    best_prompt = prompts  # Since we now store only the top prompt per index\n    print(f\"Training and evaluating for best prompt embedding index: {idx}\")\n    print(f\"Most similar prompt: {best_prompt}\")\n\n    # Function to tokenize text with the given prompt\n    def tokenize_with_prompt(examples):\n        inputs = [f\"{best_prompt} {text}\" for text in examples['text']]\n        return tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n\n    # Apply the tokenize function to datasets\n    train_data_with_prompt = train_dataset.map(tokenize_with_prompt, batched=True)\n    val_data_with_prompt = val_dataset.map(tokenize_with_prompt, batched=True)\n    test_data_with_prompt = test_dataset.map(tokenize_with_prompt, batched=True)\n\n    # Initialize the Trainer\n    trainer2 = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data_with_prompt,\n        eval_dataset= val_data_with_prompt,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    # Train the model\n    trainer2.train()\n\n    # Evaluate the model on the test set\n    eval_result = trainer2.evaluate(test_data_with_prompt)\n    print(f\"Final evaluation results for prompt index {idx} on test set: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:31:43.725613Z","iopub.execute_input":"2024-07-23T17:31:43.726011Z","iopub.status.idle":"2024-07-23T17:50:13.090689Z","shell.execute_reply.started":"2024-07-23T17:31:43.725975Z","shell.execute_reply":"2024-07-23T17:50:13.089813Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Training and evaluating for best prompt embedding index: 0\nMost similar prompt: What is the central focus of this newspaper article?\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd08988899fd45f7b38b5a05b6eca3b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29dfd5f0df648b0ac888fbc74de9e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef7021c382542d880e944b909b30066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:54, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.233519</td>\n      <td>0.964126</td>\n      <td>0.964141</td>\n      <td>0.965678</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.187503</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.254947</td>\n      <td>0.964126</td>\n      <td>0.963962</td>\n      <td>0.965314</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.256915</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.225371</td>\n      <td>0.973094</td>\n      <td>0.973047</td>\n      <td>0.973188</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.012500</td>\n      <td>0.260074</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.012500</td>\n      <td>0.215324</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.012500</td>\n      <td>0.228289</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.012500</td>\n      <td>0.224653</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.012500</td>\n      <td>0.224737</td>\n      <td>0.977578</td>\n      <td>0.977487</td>\n      <td>0.977668</td>\n      <td>0.977578</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 0 on test set: {'eval_loss': 0.23485995829105377, 'eval_accuracy': 0.9640449438202248, 'eval_f1': 0.9641472977323435, 'eval_precision': 0.965104132818141, 'eval_recall': 0.9640449438202248, 'eval_runtime': 4.5021, 'eval_samples_per_second': 98.843, 'eval_steps_per_second': 6.219, 'epoch': 10.0}\nTraining and evaluating for best prompt embedding index: 35\nMost similar prompt: What is the main point of this press article?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8aae20571d413ab3cb96366414a00e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab0d0a629b24b60a3d8e572e0a727c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1a3030663a45e98e66f33262235b15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:54, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.262480</td>\n      <td>0.973094</td>\n      <td>0.972855</td>\n      <td>0.974410</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.171806</td>\n      <td>0.982063</td>\n      <td>0.982016</td>\n      <td>0.982059</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.237821</td>\n      <td>0.968610</td>\n      <td>0.968375</td>\n      <td>0.969527</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.238301</td>\n      <td>0.964126</td>\n      <td>0.963941</td>\n      <td>0.964529</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.200724</td>\n      <td>0.968610</td>\n      <td>0.968490</td>\n      <td>0.968751</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.007700</td>\n      <td>0.212668</td>\n      <td>0.968610</td>\n      <td>0.968375</td>\n      <td>0.969200</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.007700</td>\n      <td>0.220655</td>\n      <td>0.968610</td>\n      <td>0.968375</td>\n      <td>0.969200</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.007700</td>\n      <td>0.219982</td>\n      <td>0.968610</td>\n      <td>0.968375</td>\n      <td>0.969200</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.007700</td>\n      <td>0.263501</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.007700</td>\n      <td>0.260381</td>\n      <td>0.968610</td>\n      <td>0.968215</td>\n      <td>0.970295</td>\n      <td>0.968610</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 35 on test set: {'eval_loss': 0.2860390841960907, 'eval_accuracy': 0.9617977528089887, 'eval_f1': 0.9619290885494608, 'eval_precision': 0.9637203608509256, 'eval_recall': 0.9617977528089887, 'eval_runtime': 4.5216, 'eval_samples_per_second': 98.417, 'eval_steps_per_second': 6.193, 'epoch': 10.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"def classify_article_with_prompt_embedding(prompt_embedding, article_text):\n    prompt_text = \" \".join(map(str, prompt_embedding))\n    input_text = f\"{prompt_text} {article_text}\"\n    inputs = tokenizer(input_text, truncation=True, max_length=512, padding='max_length', return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    label_id = outputs.logits.argmax(dim=1).item()\n    return label_id\n\ndef evaluate_prompt_embedding(prompt_embedding):\n    predictions = [classify_article_with_prompt_embedding(prompt_embedding, article_text) for article_text in train_dataset['text']]\n    return accuracy_score(train_dataset['label'], predictions)\n\n# Bayesian optimization function\ndef black_box_function(prompt_idx):\n    prompt_embedding = prompt_embeddings1[int(prompt_idx)]\n    return evaluate_prompt_embedding(prompt_embedding)\n\npbounds = {'prompt_idx': (0, len(prompt_embeddings1) - 1)}\n\noptimizer = BayesianOptimization(\n    f=black_box_function,\n    pbounds=pbounds,\n    random_state=42,\n)\n\noptimizer.maximize(\n    init_points=5,\n    n_iter=15,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T17:50:13.091921Z","iopub.execute_input":"2024-07-23T17:50:13.092209Z","iopub.status.idle":"2024-07-23T18:02:51.852860Z","shell.execute_reply.started":"2024-07-23T17:50:13.092184Z","shell.execute_reply":"2024-07-23T18:02:51.851895Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"|   iter    |  target   | prompt... |\n-------------------------------------\n| \u001b[30m1         | \u001b[30m0.1843    | \u001b[30m35.58     |\n| \u001b[30m2         | \u001b[30m0.1747    | \u001b[30m90.32     |\n| \u001b[30m3         | \u001b[30m0.1843    | \u001b[30m69.54     |\n| \u001b[30m4         | \u001b[30m0.1843    | \u001b[30m56.87     |\n| \u001b[30m5         | \u001b[30m0.1843    | \u001b[30m14.82     |\n| \u001b[30m6         | \u001b[30m0.1843    | \u001b[30m0.0       |\n| \u001b[30m7         | \u001b[30m0.1747    | \u001b[30m12.96     |\n| \u001b[30m8         | \u001b[30m0.1843    | \u001b[30m34.66     |\n| \u001b[30m9         | \u001b[30m0.1843    | \u001b[30m16.17     |\n| \u001b[35m10        | \u001b[35m0.2351    | \u001b[35m71.57     |\n| \u001b[30m11        | \u001b[30m0.2351    | \u001b[30m72.26     |\n| \u001b[30m12        | \u001b[30m0.1747    | \u001b[30m74.37     |\n| \u001b[30m13        | \u001b[30m0.2351    | \u001b[30m71.91     |\n| \u001b[30m14        | \u001b[30m0.1843    | \u001b[30m46.12     |\n| \u001b[30m15        | \u001b[30m0.2351    | \u001b[30m25.51     |\n| \u001b[30m16        | \u001b[30m0.2351    | \u001b[30m26.96     |\n| \u001b[30m17        | \u001b[30m0.1843    | \u001b[30m23.5      |\n| \u001b[30m18        | \u001b[30m0.1843    | \u001b[30m28.8      |\n| \u001b[30m19        | \u001b[30m0.2351    | \u001b[30m26.23     |\n| \u001b[30m20        | \u001b[30m0.1843    | \u001b[30m82.52     |\n=====================================\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Find the maximum target value\nmax_target_value = max(res['target'] for res in optimizer.res)\n\n# Step 2: Collect all unique prompt indices with the maximum target value\nbest_prompt_indices = [int(res['params']['prompt_idx']) for res in optimizer.res if res['target'] == max_target_value]\nunique_best_prompt_indices = list(set(best_prompt_indices))\n\n# Step 3: Get the unique embeddings\nbest_prompt_embeddings = [prompt_embeddings1[idx] for idx in unique_best_prompt_indices]\n\n# Step 4: Find the top one most similar prompt for each of the best embeddings\nall_top_similar_prompts_dict = {}\n\nfor idx, best_prompt_embedding in enumerate(best_prompt_embeddings):\n    similarities = cosine_similarity(best_prompt_embedding[np.newaxis, :], prompt_embeddings1)[0]\n    # Get the index of the most similar prompt for each best embedding\n    top_index = np.argmax(similarities)\n    # Collect the most similar prompt\n    top_similar_prompt = enhanced_prompts1[top_index]\n    all_top_similar_prompts_dict[unique_best_prompt_indices[idx]] = top_similar_prompt\n\n# Output best prompt embedding indices and their corresponding top one similar prompts\nprint(\"Best prompt embedding indices and their top one similar prompts:\")\nfor index, prompt in all_top_similar_prompts_dict.items():\n    print(f\"Index: {index}, Top Similar Prompt: {prompt}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:02:51.854133Z","iopub.execute_input":"2024-07-23T18:02:51.854800Z","iopub.status.idle":"2024-07-23T18:02:51.868709Z","shell.execute_reply.started":"2024-07-23T18:02:51.854766Z","shell.execute_reply":"2024-07-23T18:02:51.867466Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Best prompt embedding indices and their top one similar prompts:\nIndex: 72, Top Similar Prompt: Which category is the best match for this news article: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\nIndex: 25, Top Similar Prompt: What is the main emphasis of this news article?\nIndex: 26, Top Similar Prompt: What is the central focus of this news article?\nIndex: 71, Top Similar Prompt: Under which category does this news article best fit: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    seed= seed,\n)\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Iterate over each index and its most similar prompt\nfor idx, prompts in all_top_similar_prompts_dict.items():\n    best_prompt = prompts  # Since we now store only the top prompt per index\n    print(f\"Training and evaluating for best prompt embedding index: {idx}\")\n    print(f\"Most similar prompt: {best_prompt}\")\n\n    # Function to tokenize text with the given prompt\n    def tokenize_with_prompt(examples):\n        inputs = [f\"{best_prompt} {text}\" for text in examples['text']]\n        return tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n\n    # Apply the tokenize function to datasets\n    train_data_with_prompt1 = train_dataset.map(tokenize_with_prompt, batched=True)\n    val_data_with_prompt1 = val_dataset.map(tokenize_with_prompt, batched=True)\n    test_data_with_prompt1 = test_dataset.map(tokenize_with_prompt, batched=True)\n\n    # Initialize the Trainer\n    trainer3 = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data_with_prompt1,\n        eval_dataset=val_data_with_prompt1,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    # Train the model\n    trainer3.train()\n\n    # Evaluate the model on the test set\n    eval_result = trainer3.evaluate(test_data_with_prompt1)\n    print(f\"Final evaluation results for prompt index {idx} on test set: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:02:51.870464Z","iopub.execute_input":"2024-07-23T18:02:51.871769Z","iopub.status.idle":"2024-07-23T18:39:53.967173Z","shell.execute_reply.started":"2024-07-23T18:02:51.871714Z","shell.execute_reply":"2024-07-23T18:39:53.966361Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Training and evaluating for best prompt embedding index: 72\nMost similar prompt: Which category is the best match for this news article: business, entertainment, politics, sport or tech? Example: 'tough rules for ringtone sellers firms that flout rules on how ringtones and other mobile extras are sold could be cut off from all uk phone networks' is tech.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5530502172664636801875d912db0cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e994f82c89147b0b9a038c165986fd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e94b630463241d3adeb40dfbfd82363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:54, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229228</td>\n      <td>0.959641</td>\n      <td>0.959662</td>\n      <td>0.960879</td>\n      <td>0.959641</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.248217</td>\n      <td>0.964126</td>\n      <td>0.964042</td>\n      <td>0.965482</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.344447</td>\n      <td>0.959641</td>\n      <td>0.958718</td>\n      <td>0.961966</td>\n      <td>0.959641</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.227459</td>\n      <td>0.968610</td>\n      <td>0.968418</td>\n      <td>0.969520</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.269505</td>\n      <td>0.964126</td>\n      <td>0.963564</td>\n      <td>0.966348</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.009500</td>\n      <td>0.220720</td>\n      <td>0.977578</td>\n      <td>0.977413</td>\n      <td>0.978331</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.009500</td>\n      <td>0.242034</td>\n      <td>0.973094</td>\n      <td>0.972826</td>\n      <td>0.974216</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.009500</td>\n      <td>0.253615</td>\n      <td>0.973094</td>\n      <td>0.972826</td>\n      <td>0.974216</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.009500</td>\n      <td>0.231609</td>\n      <td>0.977578</td>\n      <td>0.977491</td>\n      <td>0.977789</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.009500</td>\n      <td>0.230935</td>\n      <td>0.977578</td>\n      <td>0.977491</td>\n      <td>0.977789</td>\n      <td>0.977578</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 72 on test set: {'eval_loss': 0.22063322365283966, 'eval_accuracy': 0.9707865168539326, 'eval_f1': 0.9708775510970766, 'eval_precision': 0.9718894430656104, 'eval_recall': 0.9707865168539326, 'eval_runtime': 4.5242, 'eval_samples_per_second': 98.359, 'eval_steps_per_second': 6.189, 'epoch': 10.0}\nTraining and evaluating for best prompt embedding index: 25\nMost similar prompt: What is the main emphasis of this news article?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e76278c82904a8988af4b2b56504b00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2bc9bcdf9a040f0b558b357b90e1619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f42e1eda3f43c48f4736437a85e9a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:55, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.354948</td>\n      <td>0.964126</td>\n      <td>0.964177</td>\n      <td>0.965509</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.274983</td>\n      <td>0.964126</td>\n      <td>0.963944</td>\n      <td>0.965387</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.235526</td>\n      <td>0.977578</td>\n      <td>0.977440</td>\n      <td>0.977579</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.235037</td>\n      <td>0.982063</td>\n      <td>0.981930</td>\n      <td>0.982376</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.235932</td>\n      <td>0.982063</td>\n      <td>0.981976</td>\n      <td>0.982464</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.004100</td>\n      <td>0.259185</td>\n      <td>0.968610</td>\n      <td>0.968166</td>\n      <td>0.970021</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.004100</td>\n      <td>0.251235</td>\n      <td>0.973094</td>\n      <td>0.972958</td>\n      <td>0.973573</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.004100</td>\n      <td>0.250984</td>\n      <td>0.973094</td>\n      <td>0.972958</td>\n      <td>0.973573</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.004100</td>\n      <td>0.250078</td>\n      <td>0.968610</td>\n      <td>0.968517</td>\n      <td>0.968878</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.004100</td>\n      <td>0.276192</td>\n      <td>0.973094</td>\n      <td>0.972899</td>\n      <td>0.974403</td>\n      <td>0.973094</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 25 on test set: {'eval_loss': 0.3110635578632355, 'eval_accuracy': 0.9662921348314607, 'eval_f1': 0.9664570575260806, 'eval_precision': 0.9671378720849809, 'eval_recall': 0.9662921348314607, 'eval_runtime': 4.5074, 'eval_samples_per_second': 98.727, 'eval_steps_per_second': 6.212, 'epoch': 10.0}\nTraining and evaluating for best prompt embedding index: 26\nMost similar prompt: What is the central focus of this news article?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38354c1da6c541b0989003c9b7945bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39edd700c9db42e78e3a42e0e4ef9040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a30dcbd71b6c43bca7cccbae9661255a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:55, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.353592</td>\n      <td>0.964126</td>\n      <td>0.963200</td>\n      <td>0.966697</td>\n      <td>0.964126</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.214394</td>\n      <td>0.973094</td>\n      <td>0.973083</td>\n      <td>0.973468</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.230510</td>\n      <td>0.968610</td>\n      <td>0.968172</td>\n      <td>0.970090</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.212862</td>\n      <td>0.977578</td>\n      <td>0.977346</td>\n      <td>0.977762</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.214599</td>\n      <td>0.982063</td>\n      <td>0.981833</td>\n      <td>0.982660</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.011500</td>\n      <td>0.201919</td>\n      <td>0.982063</td>\n      <td>0.981971</td>\n      <td>0.982246</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.011500</td>\n      <td>0.257801</td>\n      <td>0.982063</td>\n      <td>0.981976</td>\n      <td>0.982464</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.011500</td>\n      <td>0.222403</td>\n      <td>0.982063</td>\n      <td>0.981976</td>\n      <td>0.982464</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.011500</td>\n      <td>0.222111</td>\n      <td>0.982063</td>\n      <td>0.981976</td>\n      <td>0.982464</td>\n      <td>0.982063</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.011500</td>\n      <td>0.222210</td>\n      <td>0.982063</td>\n      <td>0.981976</td>\n      <td>0.982464</td>\n      <td>0.982063</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 26 on test set: {'eval_loss': 0.3284412920475006, 'eval_accuracy': 0.9707865168539326, 'eval_f1': 0.9709241097638721, 'eval_precision': 0.9714714871507113, 'eval_recall': 0.9707865168539326, 'eval_runtime': 4.5097, 'eval_samples_per_second': 98.676, 'eval_steps_per_second': 6.209, 'epoch': 10.0}\nTraining and evaluating for best prompt embedding index: 71\nMost similar prompt: Under which category does this news article best fit: business, entertainment, politics, sport or tech? Example: 'wales want rugby league training wales could follow england s lead by training with a rugby league club' is sport.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b28e3b37ee6462983df7f66483c433d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/223 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a93c492d024d58928544b174d55a19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90204d057fbf48ff95515f9469102b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [980/980 08:55, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.253207</td>\n      <td>0.977578</td>\n      <td>0.977366</td>\n      <td>0.978242</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.406435</td>\n      <td>0.959641</td>\n      <td>0.959119</td>\n      <td>0.962085</td>\n      <td>0.959641</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.332637</td>\n      <td>0.973094</td>\n      <td>0.972733</td>\n      <td>0.973949</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.244615</td>\n      <td>0.968610</td>\n      <td>0.968096</td>\n      <td>0.969268</td>\n      <td>0.968610</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.265782</td>\n      <td>0.973094</td>\n      <td>0.972576</td>\n      <td>0.974492</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.004400</td>\n      <td>0.219133</td>\n      <td>0.973094</td>\n      <td>0.972861</td>\n      <td>0.973184</td>\n      <td>0.973094</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.004400</td>\n      <td>0.219774</td>\n      <td>0.977578</td>\n      <td>0.977440</td>\n      <td>0.977579</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.004400</td>\n      <td>0.219853</td>\n      <td>0.977578</td>\n      <td>0.977440</td>\n      <td>0.977579</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.004400</td>\n      <td>0.219040</td>\n      <td>0.977578</td>\n      <td>0.977440</td>\n      <td>0.977579</td>\n      <td>0.977578</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.004400</td>\n      <td>0.218970</td>\n      <td>0.977578</td>\n      <td>0.977440</td>\n      <td>0.977579</td>\n      <td>0.977578</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 71 on test set: {'eval_loss': 0.25958606600761414, 'eval_accuracy': 0.9685393258426966, 'eval_f1': 0.9686649438382771, 'eval_precision': 0.9697361668202995, 'eval_recall': 0.9685393258426966, 'eval_runtime': 4.5238, 'eval_samples_per_second': 98.368, 'eval_steps_per_second': 6.189, 'epoch': 10.0}\n","output_type":"stream"}]}]}