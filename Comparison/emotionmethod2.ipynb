{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T20:09:29.750592Z","iopub.execute_input":"2024-08-11T20:09:29.751235Z","iopub.status.idle":"2024-08-11T20:09:30.808908Z","shell.execute_reply.started":"2024-08-11T20:09:29.751200Z","shell.execute_reply":"2024-08-11T20:09:30.807849Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:09:30.810746Z","iopub.execute_input":"2024-08-11T20:09:30.811190Z","iopub.status.idle":"2024-08-11T20:09:45.912448Z","shell.execute_reply.started":"2024-08-11T20:09:30.811162Z","shell.execute_reply":"2024-08-11T20:09:45.911347Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom datasets import load_dataset, Dataset\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, GPT2Model\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom bayes_opt import BayesianOptimization\nimport random\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import defaultdict","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:09:45.913996Z","iopub.execute_input":"2024-08-11T20:09:45.914339Z","iopub.status.idle":"2024-08-11T20:10:05.721514Z","shell.execute_reply.started":"2024-08-11T20:09:45.914310Z","shell.execute_reply":"2024-08-11T20:10:05.720516Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-08-11 20:09:54.334560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-11 20:09:54.334680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-11 20:09:54.473851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# set the random seed\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:05.723785Z","iopub.execute_input":"2024-08-11T20:10:05.724365Z","iopub.status.idle":"2024-08-11T20:10:05.764705Z","shell.execute_reply.started":"2024-08-11T20:10:05.724337Z","shell.execute_reply":"2024-08-11T20:10:05.763698Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndataset = load_dataset(\"dair-ai/emotion\", \"split\")\n\n# Load each split\ntrain_dataset = dataset['train']\nval_dataset = dataset['validation']\ntest_dataset = dataset['test']\n\ndef stratified_sample(dataset, fraction):\n    label_counts = defaultdict(list)\n    \n    # Group indices by label\n    for i, example in enumerate(dataset):\n        label_counts[example['label']].append(i)\n    \n    sampled_indices = []\n    for label, indices in label_counts.items():\n        # Calculate the number of samples to draw for each label\n        sample_size = int(len(indices) * fraction)\n        sampled_indices.extend(random.sample(indices, min(sample_size, len(indices))))\n    \n    return dataset.select(sampled_indices)\n\n# Calculate the fraction size (one fifth) for each dataset\nfraction = 1 / 2\n\n# Perform stratified sampling\nsampled_train_dataset = stratified_sample(train_dataset, fraction)\nsampled_val_dataset = stratified_sample(val_dataset, fraction)\nsampled_test_dataset = stratified_sample(test_dataset, fraction)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:05.766146Z","iopub.execute_input":"2024-08-11T20:10:05.766462Z","iopub.status.idle":"2024-08-11T20:10:09.590499Z","shell.execute_reply.started":"2024-08-11T20:10:05.766430Z","shell.execute_reply":"2024-08-11T20:10:09.589727Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/9.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e21b73619e6400395af42918fd5ffaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b056d37a3714234a146b07ba25d954b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31829f276574be2bb4dfb47e1b368cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8be161f2da8e4092ad38fa8877d3ef0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109f2542c6a24d85b4e653cfc17cb1d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b24f31b1e845e09d51940025f5c7ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a756ae3f6f54d65b64fba5cec051fb5"}},"metadata":{}}]},{"cell_type":"code","source":"# Load GPT2Tokenizer and Model\ntokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n\n\n\n# Add pad_token\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nmodel = GPT2ForSequenceClassification.from_pretrained('distilgpt2', num_labels=6)\n\n# Resize token embeddings to match the tokenizer length\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Set the padding token ID in the model configuration\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:09.591530Z","iopub.execute_input":"2024-08-11T20:10:09.591817Z","iopub.status.idle":"2024-08-11T20:10:14.707534Z","shell.execute_reply.started":"2024-08-11T20:10:09.591791Z","shell.execute_reply":"2024-08-11T20:10:14.706612Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f16e66626324dfebeb90541d80e5322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0cd8eee53144e1b7063e29e3a89b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e4410b871e468fa8d080e0ff18addd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741e0ffd62b8497b9f64f8b8423c51d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd87eb666b3499193abad145bf6666a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f7292c05ac64e9388db3385d14c50c7"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"enhanced_prompts1 = [\"What is the emotion expressed in this message?\",\n\"What emotion does this message express?\",\n\"How will you feel about the message?\",\n\"What emotion does the writer express for the message?\",\n\"How is the emotion conveyed in this message?\",\n\"What feeling is communicated in this message?\",\n\"How would you describe the emotion shown in this message?\",\n\"What sentiment is conveyed in this message?\",\n\"How is the feeling expressed in this message?\",\n\"How is the emotion portrayed in this message?\",\n\"In what way is the emotion shown in this message?\",\n\"What feeling is expressed in this message?\",\n\"What feeling does this message convey?\",\n\"How does this message express emotion?\",\n\"How would you describe the emotion in this message?\",\n\"What emotion is conveyed in this message?\",\n\"What feeling does this message communicate?\",\n\"What sentiment is expressed in this message?\",\n\"How would you describe your reaction to the message?\",\n\"What is your emotional response to the message?\",\n\"How might you react emotionally to the message?\",\n\"What would your feelings be towards the message?\",\n\"How do you think you will feel about the message?\",\n\"What is your anticipated reaction to the message?\",\n\"How do you feel when you read the message?\",\n\"What feeling does the writer convey in the message?\",\n\"What sentiment does the writer express in the message?\",\n\"How does the writer express emotion in the message?\",\n\"What emotion does the author convey in the message?\",\n\"How would you describe the writer's feeling in the message?\",\n\"What emotion is the writer showing in the message?\",\n\"What sentiment does the author communicate in the message?\",\n\"What is the emotion expressed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What emotion does this message express: joy, sadness, anger, fear, love or surprise?\",\n\"How will you feel about the message: joy, sadness, anger, fear, love or surprise?\",\n\"What emotion does the writer express for the message: joy, sadness, anger, fear, love or surprise?\",\n\"How is the emotion conveyed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What feeling is communicated in this message: joy, sadness, anger, fear, love or surprise?\",\n\"How would you describe the emotion shown in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What sentiment is conveyed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"How is the feeling expressed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"How is the emotion portrayed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"In what way is the emotion shown in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What feeling is expressed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What feeling does this message convey: joy, sadness, anger, fear, love or surprise?\",\n\"How does this message express emotion: joy, sadness, anger, fear, love or surprise?\",\n\"How would you describe the emotion in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What emotion is conveyed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"What feeling does this message communicate: joy, sadness, anger, fear, love or surprise?\",\n\"What sentiment is expressed in this message: joy, sadness, anger, fear, love or surprise?\",\n\"How would you describe your reaction to the message: joy, sadness, anger, fear, love or surprise?\",\n\"What is your emotional response to the message: joy, sadness, anger, fear, love or surprise?\",\n\"How might you react emotionally to the message: joy, sadness, anger, fear, love or surprise?\",\n\"What would your feelings be towards the message: joy, sadness, anger, fear, love or surprise?\",\n\"How do you think you will feel about the message: joy, sadness, anger, fear, love or surprise?\",\n\"What is your anticipated reaction to the message: joy, sadness, anger, fear, love or surprise?\",\n\"How do you feel when you read the message: joy, sadness, anger, fear, love or surprise?\",\n\"What feeling does the writer convey in the message: joy, sadness, anger, fear, love or surprise?\",\n\"What sentiment does the writer express in the message: joy, sadness, anger, fear, love or surprise?\",\n\"How does the writer express emotion in the message: joy, sadness, anger, fear, love or surprise?\",\n\"What emotion does the author convey in the message: joy, sadness, anger, fear, love or surprise?\",\n\"How would you describe the writer's feeling in the message: joy, sadness, anger, fear, love or surprise?\",\n\"What emotion is the writer showing in the message: joy, sadness, anger, fear, love or surprise?\",\n\"What sentiment does the author communicate in the message: joy, sadness, anger, fear, love or surprise?\",\n\"What is the emotion expressed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I am ever feeling nostalgic about the fireplace I will know that it is still on the property' is love.\",\n\"What emotion does this message express: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"How will you feel about the message: joy, sadness, anger, fear, love or surprise? Example: 'I've been taking or milligrams or times recommended amount and I've fallen asleep a lot faster but I also feel like so funny' is surprise.\",\n\"What emotion does the writer express for the message: joy, sadness, anger, fear, love or surprise? Example: 'I am ever feeling nostalgic about the fireplace I will know that it is still on the property' is love.\",\n\"How is the emotion conveyed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"What feeling is communicated in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"How would you describe the emotion shown in this message: joy, sadness, anger, fear, love or surprise? Example: 'I am ever feeling nostalgic about the fireplace I will know that it is still on the property' is love.\",\n\"What sentiment is conveyed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"How is the feeling expressed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"How is the emotion portrayed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"In what way is the emotion shown in this message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"What feeling is expressed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I feel as confused about life as a teenager or as jaded as a year old man' is fear.\",\n\"What feeling does this message convey: joy, sadness, anger, fear, love or surprise? Example: 'I feel as confused about life as a teenager or as jaded as a year old man' is fear.\",\n\"How does this message express emotion: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"How would you describe the emotion in this message: joy, sadness, anger, fear, love or surprise? Example: 'I'm grabbing a minute to post I feel greedy wrong' is anger.\",\n\"What emotion is conveyed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I've been taking or milligrams or times recommended amount and I've fallen asleep a lot faster but I also feel like so funny' is surprise.\",\n\"What feeling does this message communicate: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"What sentiment is expressed in this message: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"How would you describe your reaction to the message: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"What is your emotional response to the message: joy, sadness, anger, fear, love or surprise? Example: 'I am ever feeling nostalgic about the fireplace I will know that it is still on the property' is love.\",\n\"How might you react emotionally to the message: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"What would your feelings be towards the message: joy, sadness, anger, fear, love or surprise? Example: 'I am ever feeling nostalgic about the fireplace I will know that it is still on the property' is love.\",\n\"How do you think you will feel about the message: joy, sadness, anger, fear, love or surprise? Example: 'I've been taking or milligrams or times recommended amount and I've fallen asleep a lot faster but I also feel like so funny' is surprise.\",\n\"What is your anticipated reaction to the message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"How do you feel when you read the message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"What feeling does the writer convey in the message: joy, sadness, anger, fear, love or surprise? Example: 'I'm grabbing a minute to post I feel greedy wrong' is anger.\",\n\"What sentiment does the writer express in the message: joy, sadness, anger, fear, love or surprise? Example: 'I feel as confused about life as a teenager or as jaded as a year old man' is fear.\",\n\"How does the writer express emotion in the message: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"What emotion does the author convey in the message: joy, sadness, anger, fear, love or surprise? Example: 'I have been with Petronas for years I feel that Petronas has performed well and made a huge profit' is joy.\",\n\"How would you describe the writer's feeling in the message: joy, sadness, anger, fear, love or surprise? Example: 'I didn't feel humiliated' is sadness.\",\n\"What emotion is the writer showing in the message: joy, sadness, anger, fear, love or surprise? Example: 'I feel as confused about life as a teenager or as jaded as a year old man' is fear.\",\n\"What sentiment does the author communicate in the message: joy, sadness, anger, fear, love or surprise? Example: 'I feel as confused about life as a teenager or as jaded as a year old man' is fear.\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:14.709128Z","iopub.execute_input":"2024-08-11T20:10:14.709449Z","iopub.status.idle":"2024-08-11T20:10:14.724422Z","shell.execute_reply.started":"2024-08-11T20:10:14.709422Z","shell.execute_reply":"2024-08-11T20:10:14.723418Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# load Sentence Transformer model\nembedmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# generate embeddings for each prompt\nprompt_embeddings = embedmodel.encode(enhanced_prompts1)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:14.725680Z","iopub.execute_input":"2024-08-11T20:10:14.726010Z","iopub.status.idle":"2024-08-11T20:10:18.023079Z","shell.execute_reply.started":"2024-08-11T20:10:14.725982Z","shell.execute_reply":"2024-08-11T20:10:18.021952Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f084322450b84b9fadc686509f3a4f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ba714012e742e088ef1484ed3fc12a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1451b6d4afb4c768d7e69b5097933d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650a9d8f868e4202a11f1f257beb0345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0eb857b67e740a2b18ea8cf2050b047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0027fb5439ee4fd9ab211aade5af50bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f467b6a5be304e4e939e3ab316c069a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be10ccd0b7e947818281f3412aa91cb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393fe02d17d443bf9cbc0c2e4b175d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5e7248628242d09df6a575a837bb38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5abe17ea1bb44f5827d183ae8e53ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c77bc789014230aefcf9927efad8df"}},"metadata":{}}]},{"cell_type":"code","source":"# classify function\ndef classify_article_with_prompt_embedding(prompt_embedding, article_text):\n    prompt_text = \" \".join(map(str, prompt_embedding))\n    input_text = f\"{prompt_text} {article_text}\"\n    inputs = tokenizer(input_text, truncation=True, max_length=512, padding='max_length', return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    label_id = outputs.logits.argmax(dim=1).item()\n    return label_id\n\ndef evaluate_prompt_embedding(prompt_embedding):\n    predictions = [classify_article_with_prompt_embedding(prompt_embedding, article_text) for article_text in sampled_train_dataset['text']]\n    return accuracy_score(sampled_train_dataset['label'], predictions)\n\n# Bayesian optimization function\ndef black_box_function(prompt_idx):\n    prompt_embedding = prompt_embeddings[int(prompt_idx)]\n    return evaluate_prompt_embedding(prompt_embedding)\n\npbounds = {'prompt_idx': (0, len(prompt_embeddings) - 1)}\n\noptimizer = BayesianOptimization(\n    f=black_box_function,\n    pbounds=pbounds,\n    random_state=42,\n)\n\noptimizer.maximize(\n    init_points=5,\n    n_iter=15,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:10:18.024538Z","iopub.execute_input":"2024-08-11T20:10:18.024852Z","iopub.status.idle":"2024-08-11T21:13:58.572322Z","shell.execute_reply.started":"2024-08-11T20:10:18.024823Z","shell.execute_reply":"2024-08-11T21:13:58.571249Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"|   iter    |  target   | prompt... |\n-------------------------------------\n| \u001b[30m1         | \u001b[30m0.121     | \u001b[30m35.58     |\n| \u001b[30m2         | \u001b[30m0.121     | \u001b[30m90.32     |\n| \u001b[30m3         | \u001b[30m0.121     | \u001b[30m69.54     |\n| \u001b[30m4         | \u001b[30m0.121     | \u001b[30m56.87     |\n| \u001b[30m5         | \u001b[30m0.121     | \u001b[30m14.82     |\n| \u001b[35m6         | \u001b[35m0.2917    | \u001b[35m0.001105  |\n| \u001b[30m7         | \u001b[30m0.2917    | \u001b[30m0.7833    |\n| \u001b[30m8         | \u001b[30m0.121     | \u001b[30m4.558     |\n| \u001b[30m9         | \u001b[30m0.121     | \u001b[30m46.23     |\n| \u001b[30m10        | \u001b[30m0.121     | \u001b[30m79.93     |\n| \u001b[30m11        | \u001b[30m0.121     | \u001b[30m25.2      |\n| \u001b[30m12        | \u001b[30m0.121     | \u001b[30m63.2      |\n| \u001b[30m13        | \u001b[30m0.121     | \u001b[30m1.768     |\n| \u001b[30m14        | \u001b[30m0.2917    | \u001b[30m0.3968    |\n| \u001b[30m15        | \u001b[30m0.121     | \u001b[30m51.56     |\n| \u001b[30m16        | \u001b[30m0.121     | \u001b[30m40.9      |\n| \u001b[30m17        | \u001b[30m0.121     | \u001b[30m74.74     |\n| \u001b[30m18        | \u001b[30m0.121     | \u001b[30m85.13     |\n| \u001b[30m19        | \u001b[30m0.121     | \u001b[30m30.4      |\n| \u001b[30m20        | \u001b[30m0.2917    | \u001b[30m0.6101    |\n=====================================\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Find the maximum target value\nmax_target_value = max(res['target'] for res in optimizer.res)\n\n# Step 2: Collect all unique prompt indices with the maximum target value\nbest_prompt_indices = [int(res['params']['prompt_idx']) for res in optimizer.res if res['target'] == max_target_value]\nunique_best_prompt_indices = list(set(best_prompt_indices))\n\n# Step 3: Get the unique embeddings\nbest_prompt_embeddings = [prompt_embeddings[idx] for idx in unique_best_prompt_indices]\n\n# Step 4: Find the top one most similar prompt for each of the best embeddings\nall_top_similar_prompts_dict = {}\n\nfor idx, best_prompt_embedding in enumerate(best_prompt_embeddings):\n    similarities = cosine_similarity(best_prompt_embedding[np.newaxis, :], prompt_embeddings)[0]\n    # Get the index of the most similar prompt for each best embedding\n    top_index = np.argmax(similarities)\n    # Collect the most similar prompt\n    top_similar_prompt = enhanced_prompts1[top_index]\n    all_top_similar_prompts_dict[unique_best_prompt_indices[idx]] = top_similar_prompt\n\n# Output best prompt embedding indices and their corresponding top one similar prompts\nprint(\"Best prompt embedding indices and their top one similar prompts:\")\nfor index, prompt in all_top_similar_prompts_dict.items():\n    print(f\"Index: {index}, Top Similar Prompt: {prompt}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T21:13:58.575061Z","iopub.execute_input":"2024-08-11T21:13:58.575367Z","iopub.status.idle":"2024-08-11T21:13:58.589539Z","shell.execute_reply.started":"2024-08-11T21:13:58.575341Z","shell.execute_reply":"2024-08-11T21:13:58.588428Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Best prompt embedding indices and their top one similar prompts:\nIndex: 0, Top Similar Prompt: What is the emotion expressed in this message?\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define compute metrics function\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.argmax(axis=1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n    acc = accuracy_score(labels, predictions)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    seed= seed,\n)\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Iterate over each index and its most similar prompt\nfor idx, prompts in all_top_similar_prompts_dict.items():\n    best_prompt = prompts  # Since we now store only the top prompt per index\n    print(f\"Training and evaluating for best prompt embedding index: {idx}\")\n    print(f\"Most similar prompt: {best_prompt}\")\n\n    # Function to tokenize text with the given prompt\n    def tokenize_with_prompt(examples):\n        inputs = [f\"{best_prompt} {text}\" for text in examples['text']]\n        return tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n\n    # Apply the tokenize function to datasets\n    train_data_with_prompt = sampled_train_dataset.map(tokenize_with_prompt, batched=True)\n    val_data_with_prompt = sampled_val_dataset.map(tokenize_with_prompt, batched=True)\n    test_data_with_prompt = sampled_test_dataset.map(tokenize_with_prompt, batched=True)\n\n    # Initialize the Trainer\n    trainer2 = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data_with_prompt,\n        eval_dataset= val_data_with_prompt,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    # Train the model\n    trainer2.train()\n\n    # Evaluate the model on the test set\n    eval_result = trainer2.evaluate(test_data_with_prompt)\n    print(f\"Final evaluation results for prompt index {idx} on test set: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T21:23:11.072837Z","iopub.execute_input":"2024-08-11T21:23:11.073567Z","iopub.status.idle":"2024-08-11T22:07:31.010082Z","shell.execute_reply.started":"2024-08-11T21:23:11.073531Z","shell.execute_reply":"2024-08-11T22:07:31.008899Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training and evaluating for best prompt embedding index: 0\nMost similar prompt: What is the emotion expressed in this message?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5000/5000 44:01, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.173500</td>\n      <td>0.483395</td>\n      <td>0.855856</td>\n      <td>0.850598</td>\n      <td>0.861540</td>\n      <td>0.855856</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.401100</td>\n      <td>0.265568</td>\n      <td>0.911912</td>\n      <td>0.911823</td>\n      <td>0.912975</td>\n      <td>0.911912</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.232900</td>\n      <td>0.214836</td>\n      <td>0.916917</td>\n      <td>0.916305</td>\n      <td>0.917325</td>\n      <td>0.916917</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.174900</td>\n      <td>0.189180</td>\n      <td>0.927928</td>\n      <td>0.928181</td>\n      <td>0.929241</td>\n      <td>0.927928</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.145700</td>\n      <td>0.189355</td>\n      <td>0.931932</td>\n      <td>0.931585</td>\n      <td>0.931671</td>\n      <td>0.931932</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.129200</td>\n      <td>0.216408</td>\n      <td>0.930931</td>\n      <td>0.930687</td>\n      <td>0.931284</td>\n      <td>0.930931</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.111900</td>\n      <td>0.210440</td>\n      <td>0.922923</td>\n      <td>0.923387</td>\n      <td>0.925085</td>\n      <td>0.922923</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.104500</td>\n      <td>0.215408</td>\n      <td>0.924925</td>\n      <td>0.924539</td>\n      <td>0.925436</td>\n      <td>0.924925</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.083800</td>\n      <td>0.206583</td>\n      <td>0.928929</td>\n      <td>0.928061</td>\n      <td>0.928512</td>\n      <td>0.928929</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.085800</td>\n      <td>0.204452</td>\n      <td>0.922923</td>\n      <td>0.922579</td>\n      <td>0.922876</td>\n      <td>0.922923</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:10]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results for prompt index 0 on test set: {'eval_loss': 0.21594026684761047, 'eval_accuracy': 0.9248496993987976, 'eval_f1': 0.9247668686374074, 'eval_precision': 0.9248156699709753, 'eval_recall': 0.9248496993987976, 'eval_runtime': 10.3113, 'eval_samples_per_second': 96.787, 'eval_steps_per_second': 6.11, 'epoch': 10.0}\n","output_type":"stream"}]}]}